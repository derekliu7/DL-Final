{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from scipy.misc import imresize\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from sklearn.utils import compute_class_weight\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Dropout, Activation\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jpg</th>\n",
       "      <th>video</th>\n",
       "      <th>interesting</th>\n",
       "      <th>level</th>\n",
       "      <th>key_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107_102-113.jpg</td>\n",
       "      <td>video_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099801</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129_114-144.jpg</td>\n",
       "      <td>video_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029117</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               jpg    video  interesting     level  key_frame\n",
       "0  107_102-113.jpg  video_0            0  0.099801         36\n",
       "1  129_114-144.jpg  video_0            0  0.029117         46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_label(path):\n",
    "    label = pd.read_table(path, sep=',', header=None)\n",
    "    label.columns=['video','jpg', 'interesting', 'level', 'key_frame']\n",
    "    label = label.groupby(['jpg'], sort=False, as_index=False).max()\n",
    "    return label\n",
    "\n",
    "train_label = load_label('data/devset-image.txt')\n",
    "test_label = load_label('data/testset-image.txt')\n",
    "\n",
    "train_label.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.load('data/train_array.npy')\n",
    "y = np.array(train_label['interesting'])\n",
    "test = np.load('data/test_array.npy')\n",
    "y_test = np.array(test_label['interesting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     display(array_to_img(train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.read_csv('weights_history.csv')\n",
    "# del check['Unnamed: 0']\n",
    "# print(check)\n",
    "# check.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55267278  5.2462845 ]\n"
     ]
    }
   ],
   "source": [
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "print(weights)\n",
    "# plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 214, 382, 64)      1792      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 214, 382, 64)      0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 214, 382, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 107, 191, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 105, 189, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 105, 189, 64)      0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 105, 189, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 52, 94, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 312832)            0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 312832)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 312832)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 625666    \n",
      "=================================================================\n",
      "Total params: 664,386.0\n",
      "Trainable params: 664,386.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DL/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(216, 384, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(Dense(2, activation='softmax', W_regularizer=l2(0.5)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, (5, 5), input_shape=(216, 384, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(2, activation = 'softmax', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3 = VGG19(weights='imagenet', include_top=False,\n",
    "#                      input_shape=(216, 384, 3))\n",
    "\n",
    "# x = Flatten(name='flatten')(v3.layers[-3].output)\n",
    "# x = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "# model = Model(inputs=v3.input, outputs=x)\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     if layer.name in ['drop','flatten','predictions']:\n",
    "#         continue\n",
    "#     layer.trainable = False\n",
    "\n",
    "# df = pd.DataFrame(([layer.name, layer.trainable] for layer in model.layers), columns=['layer', 'trainable'])\n",
    "# df.style.applymap(lambda trainable: f'background-color: {\"white\" if trainable else \"lightblue\"}', subset=['trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4447 samples, validate on 495 samples\n",
      "Epoch 1/5\n",
      "4447/4447 [==============================] - 729s - loss: 2.4019 - precision: 0.8989 - recall: 0.8988 - val_loss: 2.0385 - val_precision: 0.9091 - val_recall: 0.9091\n",
      "Epoch 2/5\n",
      "4447/4447 [==============================] - 729s - loss: 2.0705 - precision: 0.9031 - recall: 0.9031 - val_loss: 1.7713 - val_precision: 0.9172 - val_recall: 0.9172\n",
      "Epoch 3/5\n",
      "4447/4447 [==============================] - 728s - loss: 1.8680 - precision: 0.9033 - recall: 0.9033 - val_loss: 1.5986 - val_precision: 0.9172 - val_recall: 0.9172\n",
      "Epoch 4/5\n",
      "4447/4447 [==============================] - 726s - loss: 1.7589 - precision: 0.9033 - recall: 0.9033 - val_loss: 1.5263 - val_precision: 0.9172 - val_recall: 0.9172\n",
      "Epoch 5/5\n",
      "4447/4447 [==============================] - 727s - loss: 3.2356 - precision: 0.8842 - recall: 0.8842 - val_loss: 3.2972 - val_precision: 0.9172 - val_recall: 0.9172\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "             metrics=[precision, recall])\n",
    "\n",
    "history = model.fit(train, \n",
    "                    to_categorical(y),\n",
    "                    validation_split=.1, \n",
    "                    epochs=5, \n",
    "                    class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2314}) 0.895851339672\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDIAkNWUAJKkpAyBJTRkASWrKAEhSU/8H1Sah5z3LlHcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b64f6e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outcome = np.argmax(preds, axis=1)\n",
    "plt.hist(np.argmax(preds, axis=1))\n",
    "print(Counter(outcome), sum(outcome==y_test)/len(y_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
