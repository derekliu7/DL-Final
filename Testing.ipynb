{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from scipy.misc import imresize\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(path):\n",
    "    label = pd.read_table(path, sep=',', header=None)\n",
    "    label.columns=['video','jpg', 'interesting', 'level', 'key_frame']\n",
    "    label = label.groupby(['jpg'], sort=False, as_index=False).max()\n",
    "    return label\n",
    "\n",
    "train_label = load_label('data/devset-image.txt')\n",
    "test_label = load_label('data/testset-image.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if beta < 0:\n",
    "     raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "     return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Optimizer weight shape (96,) not compatible with provided weight shape (32,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3d29d208e0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fbeta_score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0moptimizer_weight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0moptimizer_weight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weight_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Optimizer weight shape (96,) not compatible with provided weight shape (32,)"
     ]
    }
   ],
   "source": [
    "model = load_model('weights.h5', custom_objects={'precision': precision, 'recall': recall, 'fbeta_score': fbeta_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.load('test_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 24s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.50508934736251831, 0.88]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test, to_categorical(test_label['interesting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56b853f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_label['interesting'][:100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89880919,  0.10142256],\n",
       "       [ 0.89880919,  0.10142265],\n",
       "       [ 0.89880902,  0.10142282],\n",
       "       [ 0.89880931,  0.10142249],\n",
       "       [ 0.89880931,  0.10142247],\n",
       "       [ 0.89880913,  0.10142265],\n",
       "       [ 0.89880919,  0.1014226 ],\n",
       "       [ 0.89880919,  0.10142256],\n",
       "       [ 0.89880902,  0.10142278],\n",
       "       [ 0.89880902,  0.10142278],\n",
       "       [ 0.89880902,  0.10142276],\n",
       "       [ 0.89880902,  0.10142269],\n",
       "       [ 0.89880621,  0.10142505],\n",
       "       [ 0.89880902,  0.10142273],\n",
       "       [ 0.89880902,  0.10142279],\n",
       "       [ 0.89880913,  0.10142267],\n",
       "       [ 0.89880902,  0.1014227 ],\n",
       "       [ 0.89880919,  0.1014226 ],\n",
       "       [ 0.89880902,  0.10142273],\n",
       "       [ 0.89880913,  0.10142267]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    1\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    1\n",
       "Name: interesting, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label['interesting'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flat(list_):\n",
    "    list_a = []\n",
    "    for i in list_:\n",
    "        list_a.append(i.flatten())\n",
    "    return list_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.load('train_array.npy')\n",
    "train_flat = flat(train)\n",
    "y = np.array(train_label['interesting'])\n",
    "a=np.array(train_flat)\n",
    "y = np.reshape(y, (4942,1))\n",
    "new_array = np.hstack((a,y))\n",
    "ind = np.argsort(new_array[:,-1])\n",
    "new_array = new_array[ind]\n",
    "np.save('sorted_array', new_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
